{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project in progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For now, API below does not request for any data.\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from utils import load_galaxy_data\n",
    "\n",
    "import requests\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#Loads data from url\n",
    "def make_request(url):\n",
    "    print(\"Requesting data from {}...\".format(url))\n",
    "    response = requests.get('https://content.codecademy.com/courses/deeplearning-with-tensorflow/'+url)\n",
    "    response.raise_for_status()\n",
    "    response_data = io.BytesIO(response.content)\n",
    "    return response_data\n",
    "    \n",
    "#Loads galaxy data\n",
    "def load_galaxy_data():\n",
    "  \n",
    "  #If cached file not found, loads data from url\n",
    "  if not os.path.isfile('./cached_data.npz'):\n",
    "     response_data = make_request(url='galaxydata.npz')\n",
    "\n",
    "     with open(\"cached_data.npz\",\"wb\") as save_file:\n",
    "      save_file.write(response_data.read())\n",
    " \n",
    "  #Load data using NumPy\n",
    "  data = np.load('cached_data.npz')\n",
    "\n",
    "  print(\"Successfully loaded galaxy data!\")\n",
    "  \n",
    "  return data[\"data\"],data[\"labels\"]\n",
    "\n",
    "input_data, labels = load_galaxy_data()\n",
    "print(input_data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(input_data, labels, test_size = 0.2, shuffle = True, random_state = 42, startify = labels)\n",
    "#Stratifying data ensures that ratios of galaxies in my testing data will be the same as in the original dataset.\n",
    "\n",
    "print(x_train)\n",
    "print(x_valid)\n",
    "print(y_train)\n",
    "print(y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It generates batches of tensor image data with real-time data augmentation. Most of the rest parameters are left default. \n",
    "\n",
    "data_generator = ImageDataGenerator(rescale = 1.0/255)\n",
    "#ImageDataGenerator object will normalize the pixels using the rescale parameter. (Our images are made of 255 pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating NumpyArrayIterators by flow method of ImageDataGenerator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flow is the method that takes numpy data & label arrays, and generates batches of augmented/normalized data. Yields batches indefinitely, in an infinite loop.\n",
    "\n",
    "train_data_iterator = data_generator.flow(x_train, y_train, batch_size = 5)\n",
    "valid_data_iterator = data_generator.flow(x_valid, y_valid, batch_size = 5)\n",
    "\n",
    "print(train_data_iterator)\n",
    "print(valid_data_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input(shape = (128, 128, 3)))\n",
    "\n",
    "#Adding 2D convolutional layer with convolution step (stride) equal to 2, processing 128x128 RGB images into tensor output.\n",
    "model.add(tf.keras.layers.Conv2D(8, 3, strides = 2, activation = 'relu'))\n",
    "\n",
    "#Adding 2D max pooling layer.\n",
    "#ownsamples the input along its spatial dimensions (height and width) by taking the maximum value over an input window (of size defined by pool_size) for each channel of the input.\n",
    "#The window is shifted by strides along each dimension.\n",
    "model.add(tf.keras.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "#Adding flattening layer. The layer flattening the input.\n",
    "model.add(tf.keras.Flatten())\n",
    "model.add(tf.keras.Dense(16, activation = 'relu'))\n",
    "\n",
    "#Output layer with softmax activation function turning it's input into probability distribution.\n",
    "model.add(tf.keras.Dense(4, activation = 'softmax'))\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optmizer = tf.keras.optimizers.Adam(learning_rate = 0.001),\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics = [tf.keras.metrics.CategoricalAccuracy(),tf.keras.metrics.AUC()]\n",
    ")\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_data_interator,\n",
    "    steps_per_epoch = len(x_train)/5,\n",
    "    epochs = 8,\n",
    "    validation_data = valid_data_iterator,\n",
    "    validation_steps = len(x_valid)/5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing how neural network processing images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code chunck loads in sample data, uses your model to make predictions, and then saves the feature maps from each convolutional layer. \n",
    "#These feature maps showcase the activations of each filter as they are convolved across the input.\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#Visualizes convolutional layer activations\n",
    "def visualize_activations(model, valid_iterator):\n",
    "\n",
    "  #A keras model that will output our previous model's activations for each convolutional layer:\n",
    "  activation_extractor = tf.keras.Model(inputs=model.inputs, outputs=[layer.output for layer in model.layers if \"conv2d\" in layer.name])\n",
    "\n",
    "  #Take matplotlib frame and remove axes.\n",
    "  def clean_plot(plot):\n",
    "    plot.axes.get_xaxis().set_visible(False)\n",
    "    plot.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "  #Dict mapping from class numbers to string labels:\n",
    "  class_names = {0:\"Regular\",1:\"Ringed\",2:\"Merger\",3:\"Other\"}\n",
    "\n",
    "  #Loads a sample batch of data\n",
    "  sample_batch_input,sample_labels = validation_iterator.next()\n",
    " \n",
    "  #Grabs the first five images\n",
    "  sample_batch_input = sample_batch_input[:5]\n",
    "  sample_labels = sample_labels[:5]\n",
    "\n",
    "  #Makes predictions using model.predict(x)\n",
    "  sample_predictions = model.predict(sample_batch_input)\n",
    "\n",
    "  #Iterate of images, predictions, and true labels\n",
    "  for i,(image, prediction, label) in enumerate(zip(sample_batch_input, sample_predictions, sample_labels)):\n",
    "\n",
    "    image_name = \"Galaxy_{}\".format(i)\n",
    "\n",
    "    #Gets predicted class with highest probability\n",
    "\n",
    "    predicted_class = tf.argmax(prediction).numpy()\n",
    "\n",
    "    #Gets correct label\n",
    "    actual_class = tf.argmax(label).numpy()\n",
    "\n",
    "    print(image_name)\n",
    "    print(\"\\tModel prediction: {}\".format(prediction))\n",
    "    print(\"\\tTrue label: {} ({})\".format(class_names[actual_class], actual_class))\n",
    "    print(\"\\tCorrect:\", predicted_class == actual_class)\n",
    "\n",
    "    #Saves image file using matplotlib\n",
    "    sample_image = image\n",
    "    clean_plot(plt.imshow(sample_image))\n",
    "\n",
    "    plt.title(image_name+\" Predicted: {}, Actual: {}\".format(class_names[predicted_class], class_names[actual_class]))\n",
    "    plt.savefig('static/images/'+image_name+\".png\")\n",
    "    model_layer_output = activation_extractor(tf.expand_dims(sample_image,0))\n",
    "    \n",
    "    plt.clf()\n",
    "\n",
    "    #Iterates over each layer output\n",
    "    for l_num,output_data in enumerate(model_layer_output):\n",
    "\n",
    "      #Creates a subplot for each filter\n",
    "      fig, axs = plt.subplots(1, output_data.shape[-1])\n",
    "      \n",
    "      #For each filter\n",
    "      for i in range(output_data.shape[-1]):\n",
    "\n",
    "        #Plots the filter's activations\n",
    "        \n",
    "        clean_plot(axs[i].imshow(output_data[0][:, :, i], cmap=\"gray\"))\n",
    "      plt.suptitle(image_name+\" Conv {}\".format(l_num),y=0.6)\n",
    "      plt.savefig('static/images/' + image_name+ \"Conv{}.png\".format(l_num))\n",
    "      plt.clf()\n",
    "    \n",
    "visualize_activations(model,training_data_interator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
